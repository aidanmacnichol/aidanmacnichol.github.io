<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>ARM based SIMD Motion Estimation | My Portfolio</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="ARM based SIMD Motion Estimation" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/ARMbasedSIMDMotionEstimation/" />
<meta property="og:url" content="http://localhost:4000/ARMbasedSIMDMotionEstimation/" />
<meta property="og:site_name" content="My Portfolio" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="ARM based SIMD Motion Estimation" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"ARM based SIMD Motion Estimation","url":"http://localhost:4000/ARMbasedSIMDMotionEstimation/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">ARM based SIMD Motion Estimation</h1>
      <h2 class="project-tagline"></h2>
      
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="arm-optimized-motion-estimation">ARM Optimized Motion Estimation</h1>

<p>This project was done for an Embedded Systems class - SENG 440 at UVic.</p>

<p><a href="https://github.com/aidanmacnichol/SENG440-Motion-Estimation">Project Repository</a></p>

<h2 id="background">Background</h2>
<p>The goal of this project was to optimize the “sum of absolute differences” (SAD) operation. This operation is commonly used to compress videos. The general idea is to find regions in a video frame that are much different than the preceding frame. This way only changes from frame to frame are encoded instead of the entire frame itself as often most of the frame is extremely similar. This greatly improves memory and speed when encoding video:</p>

<p><img src="/assets/images/motion-estimation.png" alt="motion estimation" /></p>

<p>from: https://www.eetimes.com/how-video-compression-works/</p>

<h2 id="implementations">Implementations</h2>
<p>A few different approaches were taken for this problem:</p>

<ol>
  <li>Software optimizations</li>
  <li>Hardware based optimizations</li>
</ol>

<h3 id="hardware-based-optimizations">Hardware based optimizations</h3>
<p>The idea here is to utilize the single instruction, multiple data (SIMD) capabilities of ARM based chips. When computing SAD, the data can be packed into two SIMD vectors and the SAD can be computed 2-4x faster in parallel instead of having to loop through each vector element individually:</p>

<p><img src="/assets/images/hw_sad.png" alt="ARM SIMD" /></p>

<p>This was implemented in two ways: a <strong>Non-reentrant</strong> solution (meaning there is no global state and it is safe for simultaneous/threaded execution) and a <strong>reentrant</strong> solution (state is kept track of with a shared global variable)</p>

<p>This snippet comes from <a href="https://github.com/aidanmacnichol/SENG440-Motion-Estimation">GitHub</a>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td class="rouge-code"><pre>int hw_sad_nonreentrant(uint8_t *__restrict blockA, uint8_t *__restrict blockB) {

    uint8x16_t result; 
    uint8x16_t v_blockA; 
    uint8x16_t v_blockB; 

    // Load 16 size 8-bit into SIMD register
    v_blockA = vld1q_u8(blockA);
    v_blockB = vld1q_u8(blockB); 

    // Absolute difference between the two vectors
    result = vabdq_u8(v_blockA, v_blockB); 

    // Split the 16x8 result vector into two 8x8 vectors
    uint8x8_t result_low = vget_low_u8(result);
    uint8x8_t result_high = vget_high_u8(result);

    // Sum the lower and upper halves of the result vector
    uint8x8_t acc = vadd_u8(result_low, result_high);
    uint16x4_t acc1 = vpaddl_u8(acc);
    uint32x2_t acc2 = vpaddl_u16(acc1);

    // Calculate the total
    uint32_t sum = vget_lane_u32(acc2, 0) + vget_lane_u32(acc2, 1);

    // Return the total as an integer
    return (int)sum; }
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The highlight of this code is the <strong>vabdq_u8</strong> instruction. This calculates the unsigned absolute difference between two vectors and returns the result. In the regular software version this part takes <strong>n</strong> calculations for a vector of length <strong>n</strong>.</p>

<p>The <strong>reentrant</strong> solution is much simplier:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre>void hw_sad_reentrant(uint8_t *__restrict blockA, uint8_t *__restrict blockB, uint8x16_t *v_acc) {

    uint8x16_t v_blockA; 
    uint8x16_t v_blockB; 

    // Load 16 size 8 bit into SIMD register
    v_blockA = vld1q_u8(blockA);
    // Load 16 size 8 bit into SIMD register 2
    v_blockB = vld1q_u8(blockB); 
    // absolute difference between the two vectors + accumulate
    *v_acc = vabaq_u8(*v_acc, v_blockA, v_blockB);
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>With SIMD summation done at the end of each 16x16 block, integer addition is done 15 times less which amounts to 25x15 = <strong>375 saved instructions per 16x16 block</strong></p>

<p>Less looping and branching also means less cache and branch misses which greatly improves performance.</p>

<h3 id="hw-improvements">HW Improvements:</h3>
<p>The current bottleneck is packing vectors into SIMD registers. This takes 16 instructions and no computations can be done untill the two vectors are completely packed. A future improvement could be starting to pack the next two vectors (pixel rows) at a 2 cycle offset. This matches the amount of cycles it takes to compute the SAD so after a calculation is done the next two vectors are already packed and ready to go:</p>

<p><img src="\assets\images\simd-improvment.png" alt="SIMD improvementA" /></p>

<h3 id="software-optimizations">Software Optimizations</h3>
<p>This was not a very productive approach as gcc already does an amazing job optimizing code when compiled. The methods implemented were:</p>
<ul>
  <li>Loop unrolling</li>
  <li>Miscellaneous optimizations (predicates, reducing number of branches)</li>
</ul>



      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
